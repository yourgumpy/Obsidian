## What is perceptron?

It is an Algorithm → supervised ml → it is designed to be a dl

it can be called **Mathematical Model / function**

![[image.png]]

## **Perceptron**

==**Weights**== determine which input is more important in predicting the ==target== value. For example, if we consider two ==features==—==CGPA== and ==IQ==—to determine a student's ==placement==, their impact will be defined by the weights assigned to them. If CGPA has a weight of 4 and IQ has a weight of 2, CGPA will have a greater influence on the final placement outcome.

==**Bias**== helps adjust the output of a perceptron, even when all input values are zero. It acts like an intercept in a linear equation, allowing the model to make better predictions. For example, if CGPA and IQ determine a student’s placement, but other hidden factors also play a role, bias ensures the model doesn’t always predict zero when the inputs are low.

  

![[image 1.png]]
neuron vs perceptron


## Differences [Neuron vs Perceptron]

| Feature    | Neuron (Biological)                                               | Perceptron (Artificial)                                           |
| ---------- | ----------------------------------------------------------------- | ----------------------------------------------------------------- |
| Definition | A biological nerve cell that processes and transmits information. | A simple artificial neural network unit used in machine learning. |
| Structure  | Dendrites, soma (cell body), axon, synapses.                      | Input layer, weights, summation function, activation function.    |
| Function   | Processes electrochemical signals.                                | Computes weighted sums and applies an activation function.        |
| Learning   | Adapts via synaptic plasticity.                                   | Learns through weight adjustments (e.g., gradient descent).       |
| Complexity | Highly complex with billions of connections.                      | Simple, mostly used for binary classification.                    |

A **perceptron** is the simplest type of artificial neural network unit used for ==binary classification==. It takes multiple inputs, applies weights, sums them up, adds a bias, and passes the result through an activation function (like step function) to produce an output of either 0 or 1.

It is the foundation of more complex neural networks and is mainly used for ==linearly separable== problems.

## How Perceptron classify?

==Limitation== → just works on ==**linear / sort of linear**== datasets

Here’s your text with the equations formatted for better visibility in Notion:

---

A perceptron divides the input space using **geometrical decision boundaries** based on the number of inputs:

### **1. For 2 Inputs (**$x_1, x_2$**) →** ==**Line**== **(1D Decision Boundary)**

- The perceptron learns a **straight line** that separates two classes.
- **Equation:**
    $$W_1 x_1 + W_2 x_2 + b = 0$$
- This represents a **linear decision boundary** in a **2D plane**.

### **2. For 3 Inputs (**$x_1, x_2, x_3$**) →** ==**Plane**== **(2D Decision Boundary)**

- The perceptron forms a **plane** in 3D space.
- **Equation:**
    
    $$W_1 x_1 + W_2 x_2 + W_3 x_3 + b = 0$$
    
- The plane separates the two classes in a **3D space**.

### **3. For N Inputs (**$x_1,x_2,...,x_n$**) →** ==**Hyperplane**== **(N-1 Dimensional Decision Boundary)**

- The perceptron creates a **hyperplane** in **N-dimensional space**.
- **Equation:**
    
    $$∑i=1nWixi+b=0\sum_{i=1}^{n} W_i x_i + b = 0$$
    
- This **hyperplane** separates the two classes in an **N-dimensional feature space**.

---

## Code demo

`Importing libraries`

```Python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```

`Reading the CSV`

```Python
df = pd.read_csv('placement.csv')
print(df.shape)
df.head()
```

![[image 2.png]]

we can see dataset contains ==100 rows== and ==3 features== [cgpa, resume_score and placed]

`Visualizing the relationship between CGPA and resume score`

```Python
sns.scatterplot(x='cgpa',y='resume_score', hue='placed', data=df)
```

![[image 3.png]]

Here we can see that it is separable with a line.

`Taking the x(inputs) and y(output/target) values`

```Python
x = df.iloc[:,0:2] # select all the rows (':') and first two columns ('0:2')
y = df.iloc[:,-1] # select all the rows and last columns
```

`Selecting and train the perceptron model`

```Python
from sklearn.linear_model import Perceptron
p = Perceptron()
p.fit(x,y)
```

![[image 4.png]]

`finding the coefficients (` $w_1, w_2 )$ `and intercept/bias (b)`

```Python
p.coef_
```

array( 40.26, -36. )

→ that means $w_1 = 40.26$ and $w_2 = -36.0$

```Python
p.intercept_
```

array([-25.])

→ that means $b = -25.0$

![[image 5.png]]

`let's see the how the line drawn`

```Python
from mlxtend.plotting import plot_decision_regions
plot_decision_regions(x.values, y.values, clf=p, legend=2)
plt.show()
```

![[image 6.png]]

Though it isn’t the best output as we didn’t do any work on the dataset and the dataset is small.